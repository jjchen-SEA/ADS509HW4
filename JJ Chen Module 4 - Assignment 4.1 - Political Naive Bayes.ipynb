{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"/Users/JohnnyBlaze/2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of tables names\n",
      "\n",
      "[('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "# This code retrieves a list of tables from the SQLite databases\n",
    "\n",
    "# Getting all tables from sqlite_master\n",
    "sql_query = \"\"\"SELECT name FROM sqlite_master\n",
    "WHERE type='table';\"\"\"\n",
    "    \n",
    "# Executing our SQL query\n",
    "convention_cur.execute(sql_query)\n",
    "    \n",
    "print(\"The list of tables names\\n\")\n",
    "    \n",
    "# Printing all tables list\n",
    "print(convention_cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up stopwords and punctuation for text processing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = set(punctuation)\n",
    "\n",
    "# Function to remove stopwords from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    final_tokens = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            final_tokens.append(word)\n",
    "    return final_tokens\n",
    "\n",
    "# Function to tokenize text into a list of words\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Function to remove punctuation from text\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', punctuation))\n",
    "\n",
    "# Define a text preparation pipeline\n",
    "pipeline = [str.lower, remove_punctuation, tokenize, remove_stopwords]\n",
    "\n",
    "# Function to prepare text using a given pipeline of transformations\n",
    "def prepare(text, pipeline):\n",
    "    tokens = text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "# Fill this list up with items that are themselves lists.\n",
    "# The first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party.\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT party, text from conventions;\n",
    "    '''\n",
    ")\n",
    "\n",
    "convention_data = [[token_string, row[0]] for row in query_results for token_string in [\" \".join(prepare(row[1], pipeline))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['put opportunity zones trump tax bill would drive investment communities decades come put interest american workers especially black workers first that’s right donald trump delivered historic criminal justice reform ended policy incarceration black people decimated communities caused joe biden democrats wouldn’t obama didn’t want joe biden kamala harris definitely wouldn’t donald trump he’s also working every day make community safer former executive dekalb county georgia directed one largest public safety departments southeast',\n",
       "  'Republican'],\n",
       " ['justice strength liberty', 'Democratic'],\n",
       " ['daughter murdered parkland joe biden called share family’s grief quickly learned decency civility also learned toughness he’s beaten nra together victims gun violence nation’s youth joe biden kamala harris take nra win let’s win back freedom live without fear florida cast 57 votes bernie sanders 192 votes next president joe biden',\n",
       "  'Democratic'],\n",
       " ['important thing say survivor hear that’s became leader it’s us it’s program started vice president biden eliminate sexual assault college campuses support new generation advocates including men boys you’re silent you’re complicit we’re getting started',\n",
       "  'Democratic'],\n",
       " ['j caleb boggs popular war hero solidly republican state took joe’s campaign seriously',\n",
       "  'Democratic'],\n",
       " ['democratic party always risen country’s greatest challenges', 'Democratic'],\n",
       " ['right let’s hear champion frontline workers also happens olympic champion world cup champion megan rapinoe',\n",
       "  'Democratic'],\n",
       " ['president bring us together black white latino asian indigenous achieve future collectively want must elect joe biden tell knew joe vice president knew joe campaign trail first got know joe father friend joe’s son beau served attorneys general states delaware california great recession spoke phone nearly every day working together win back billions dollars homeowners big banks foreclosed people’s homes',\n",
       "  'Democratic'],\n",
       " ['tried holding together without reliable childcare working nearly impossible told aunt bee going quit job thought heart would break said words changed life “i can’t get tomorrow i’ll come thursday” arrived seven suitcases pekinese named buddy stayed 16 years get tonight aunt bee learned fundamental truth nobody makes yet two generations working parents later baby don’t aunt bee you’re here’s wrong build infrastructure like roads bridges communication systems people work infrastructure helps us keeps economy going',\n",
       "  'Democratic'],\n",
       " ['inaudible 00014701', 'Democratic']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    ret_dict = {t: True for t in text.split() if t in fw}\n",
    "\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20230604)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   media = True           Republ : Democr =     33.0 : 1.0\n",
      "             enforcement = True           Republ : Democr =     30.9 : 1.0\n",
      "                   votes = True           Democr : Republ =     24.4 : 1.0\n",
      "                   china = True           Republ : Democr =     19.1 : 1.0\n",
      "                   taxes = True           Republ : Democr =     16.7 : 1.0\n",
      "                 destroy = True           Republ : Democr =     16.3 : 1.0\n",
      "                freedoms = True           Republ : Democr =     15.2 : 1.0\n",
      "                    cuts = True           Republ : Democr =     14.2 : 1.0\n",
      "                    iran = True           Republ : Democr =     13.1 : 1.0\n",
      "                supports = True           Republ : Democr =     13.1 : 1.0\n",
      "                    kept = True           Republ : Democr =     12.9 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.8 : 1.0\n",
      "                    mike = True           Republ : Democr =     12.3 : 1.0\n",
      "                 chinese = True           Republ : Democr =     12.1 : 1.0\n",
      "                   enemy = True           Republ : Democr =     12.1 : 1.0\n",
      "                 liberal = True           Republ : Democr =     12.1 : 1.0\n",
      "                  lowest = True           Republ : Democr =     12.1 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     11.0 : 1.0\n",
      "               countries = True           Republ : Democr =     11.0 : 1.0\n",
      "                   drugs = True           Republ : Democr =     11.0 : 1.0\n",
      "                recently = True           Republ : Democr =     11.0 : 1.0\n",
      "               religious = True           Republ : Democr =     11.0 : 1.0\n",
      "                  signed = True           Republ : Democr =     11.0 : 1.0\n",
      "                   crime = True           Republ : Democr =     10.4 : 1.0\n",
      "                 citizen = True           Republ : Democr =     10.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting? \n",
    "\n",
    "### My Observations\n",
    "\n",
    "When I look at these results it appears that Republicans have the most charged words. The top two words used are media and enforcement. In this list the Democrats only have one charged word which is votes. We can see this list is dominated by Republican words and get an good idea of what words we see in their politics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"/Users/JohnnyBlaze/congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "tweet_data = [[token_str, tweet[1]] for tweet in results for token_str in [\" \".join(prepare(tweet[2].decode(), pipeline))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv', 'Democratic'], ['go tribe rallytogether httpstco0nxutfl9l5', 'Democratic'], ['apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqo5t0qh', 'Democratic'], ['we’re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3', 'Republican'], ['let’s make even greater kag 🇺🇸 httpstcoy9qozd5l2z', 'Republican'], ['1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory', 'Democratic'], ['congrats belliottsd new gig sd city hall glad continue serve… httpstcofkvmw3cqdi', 'Democratic'], ['really close 3500 raised toward match right whoot that’s 7000 nonmath majors room 😂 help us get httpstcotu34c472sd httpstcoqsdqkypsmc', 'Democratic'], ['today comment period potus’s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn', 'Democratic'], ['celebrated icseastla’s 22 years eastside commitment amp saluted community leaders last night’s awards dinner httpstco7v7gh8givb', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)\n",
    "\n",
    "print(tweet_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: we’re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: let’s make even greater kag 🇺🇸 httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serve… httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot that’s 7000 nonmath majors room 😂 help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potus’s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastla’s 22 years eastside commitment amp saluted community leaders last night’s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3589, 'Democratic': 689}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4657, 'Democratic': 1067})})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ \n",
    "\n",
    "This model is better at classifiying Republicans. It appears that the word list was imbalanced and heavily in favor of Republican, which might be the reason why it does a better job with classifying Republicans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
